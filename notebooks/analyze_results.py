# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: percent
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# %% [markdown]
# # Acoustic Tokenization Results Analysis
# 
# This notebook analyzes the outputs from the acoustic tokenization pipeline.

# %% [markdown]
# # Bible Audio Acoustic Tokenization - Results Analysis
# 
# This notebook analyzes the results from the acoustic tokenization pipeline:
# - **Phase 1**: Acoustic unit discovery using XLSR-53 + K-Means clustering
# - **Phase 2**: BPE tokenizer training to discover acoustic motifs/patterns
# 
# ## Dataset
# - **Source**: Portuguese Bible audio (Old and New Testament)
# - **Total segments**: 18,072 audio segments
# - **Total audio**: ~5,057 minutes (~84 hours)
# - **Acoustic units**: 100 units discovered via K-Means
# - **BPE vocabulary**: 100 motifs discovered

# %%
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from collections import Counter
import sentencepiece as spm

plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

BASE_DIR = Path("./modal_downloads")
PHASE1_DIR = BASE_DIR / "phase1_outputs"
PHASE2_DIR = BASE_DIR / "phase2_outputs"
CHECKING_DIR = BASE_DIR / "checking_outputs"

print("üìä Analysis Notebook - Bible Audio Acoustic Tokenization")
print("=" * 60)
print(f"‚úì Base directory: {BASE_DIR}")
print(f"‚úì Phase 1 outputs: {PHASE1_DIR.exists()}")
print(f"‚úì Phase 2 outputs: {PHASE2_DIR.exists()}")
print(f"‚úì Checking outputs: {CHECKING_DIR.exists()}")

# %% [markdown]
# ## 1. Motif Analysis (BPE Discovered Patterns)
# 
# The BPE tokenizer discovered 100 acoustic motifs - recurring patterns in the acoustic unit sequences. These motifs represent common sound patterns in Portuguese speech.

# %%
with open(PHASE2_DIR / "motif_analysis.json", 'r') as f:
    motif_data = json.load(f)

print("üéµ Motif Analysis Results")
print("=" * 60)
print(f"Total tokens analyzed: {motif_data['total_tokens']:,}")
print(f"Unique motifs discovered: {motif_data['unique_motifs']}")
print(f"\nTop 20 Motifs by Frequency:")
print("-" * 60)

top_motifs = motif_data['top_motifs'][:20]
for i, item in enumerate(top_motifs, 1):
    motif = item['motif']
    count = item['count']
    percentage = (count / motif_data['total_tokens']) * 100
    units_in_motif = len([u for u in motif.replace("‚ñÅ", "").strip().split() if u])
    print(f"{i:2d}. {motif:30s} | Count: {count:8,} ({percentage:5.2f}%) | Units: {units_in_motif}")

# %%
motif_counts = [m['count'] for m in motif_data['top_motifs']]
motif_percentages = [(c / motif_data['total_tokens']) * 100 for c in motif_counts]

fig, axes = plt.subplots(2, 1, figsize=(14, 10))

top_n = 30
axes[0].bar(range(top_n), motif_percentages[:top_n], color='steelblue', alpha=0.7)
axes[0].set_xlabel('Motif Rank', fontsize=12)
axes[0].set_ylabel('Frequency (%)', fontsize=12)
axes[0].set_title(f'Top {top_n} Acoustic Motifs by Frequency', fontsize=14, fontweight='bold')
axes[0].set_xticks(range(top_n))
axes[0].set_xticklabels([f"M{i+1}" for i in range(top_n)], rotation=45, ha='right')
axes[0].grid(axis='y', alpha=0.3)

axes[1].hist(motif_counts, bins=50, color='coral', alpha=0.7, edgecolor='black')
axes[1].set_xlabel('Motif Frequency', fontsize=12)
axes[1].set_ylabel('Number of Motifs', fontsize=12)
axes[1].set_title('Motif Frequency Distribution (All 100 Motifs)', fontsize=14, fontweight='bold')
axes[1].set_yscale('log')
axes[1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\nüìà Statistics:")
print(f"   Most frequent motif: {motif_percentages[0]:.2f}% of all tokens")
print(f"   Top 10 motifs cover: {sum(motif_percentages[:10]):.2f}% of all tokens")
print(f"   Top 20 motifs cover: {sum(motif_percentages[:20]):.2f}% of all tokens")
print(f"   Top 50 motifs cover: {sum(motif_percentages[:50]):.2f}% of all tokens")

# %% [markdown]
# ## 2. BPE Vocabulary Analysis
# 
# Let's examine the BPE vocabulary file to see the discovered tokens.

# %%
vocab_path = PHASE2_DIR / "portuguese_bpe.vocab"

print("üìö BPE Vocabulary")
print("=" * 60)

vocab_lines = []
with open(vocab_path, 'r', encoding='utf-8') as f:
    for line in f:
        if line.strip():
            vocab_lines.append(line.strip())

print(f"Total vocabulary entries: {len(vocab_lines)}")
print(f"\nFirst 20 vocabulary entries:")
print("-" * 60)
for i, entry in enumerate(vocab_lines[:20], 1):
    print(f"{i:2d}. {entry}")

try:
    sp = spm.SentencePieceProcessor()
    sp.load(str(PHASE2_DIR / "portuguese_bpe.model"))
    print(f"\n‚úì BPE Model loaded successfully")
    print(f"   Vocabulary size: {sp.get_piece_size()}")
    print(f"\nSample tokens:")
    for i in range(min(10, sp.get_piece_size())):
        token = sp.id_to_piece(i)
        print(f"   {i:3d}: {token}")
except Exception as e:
    print(f"‚ö†Ô∏è  Could not load BPE model: {e}")

# %% [markdown]
# ## 3. Acoustic Unit Statistics
# 
# Analysis of the 100 acoustic units discovered via K-Means clustering.

# %%
with open(CHECKING_DIR / "validation_results.json", 'r') as f:
    validation = json.load(f)

print("üîç Acoustic Unit Validation")
print("=" * 60)
stats = validation['unit_stats']
print(f"Total units in sample: {stats['total_units']:,}")
print(f"Unique units found: {stats['unique_units']}/{stats['expected_unique']}")
print(f"Unit ID range: {stats['unit_range'][0]} - {stats['unit_range'][1]}")
print(f"Average sequence length: {stats['avg_sequence_length']:.1f} units")
print(f"Min sequence length: {stats['min_sequence_length']} units")
print(f"Max sequence length: {stats['max_sequence_length']} units")
print(f"Total sequences analyzed: {validation['total_sequences']}")

# %%
sample_unit_files = list((BASE_DIR / "sample_units").glob("*.units.txt"))
if sample_unit_files:
    sample_unit_file = sample_unit_files[0]
    with open(sample_unit_file, 'r') as f:
        sample_units = [int(u) for u in f.read().strip().split()]
    
    print(f"\nüìù Sample Unit Sequence Analysis")
    print("=" * 60)
    print(f"File: {sample_unit_file.name}")
    print(f"Sequence length: {len(sample_units)} units")
    print(f"First 50 units: {sample_units[:50]}")
    print(f"Last 50 units: {sample_units[-50:]}")
    
    unit_freq = Counter(sample_units)
    print(f"\nMost frequent units in this sequence:")
    for unit, count in unit_freq.most_common(10):
        print(f"   Unit {unit:3d}: {count:4d} times ({count/len(sample_units)*100:.1f}%)")
    
    fig, axes = plt.subplots(2, 1, figsize=(14, 8))
    
    axes[0].plot(sample_units[:500], alpha=0.7, linewidth=0.5)
    axes[0].set_xlabel('Position in Sequence', fontsize=12)
    axes[0].set_ylabel('Unit ID', fontsize=12)
    axes[0].set_title('Unit Sequence Over Time (First 500 units)', fontsize=14, fontweight='bold')
    axes[0].grid(alpha=0.3)
    
    axes[1].hist(sample_units, bins=100, color='teal', alpha=0.7, edgecolor='black')
    axes[1].set_xlabel('Unit ID', fontsize=12)
    axes[1].set_ylabel('Frequency', fontsize=12)
    axes[1].set_title('Unit Frequency Distribution in Sample Sequence', fontsize=14, fontweight='bold')
    axes[1].grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.show()
else:
    print("‚ö†Ô∏è  Sample unit file not found")

# %% [markdown]
# ## 5. Audio Playback & Analysis
# 
# Listen to sample audio segments and analyze their acoustic properties.

# %%
import soundfile as sf
import librosa
from IPython.display import Audio, display
import matplotlib.pyplot as plt
import numpy as np

print("üéµ Audio Playback & Analysis")
print("=" * 60)

sample_audio_dir = BASE_DIR / "sample_audio"
audio_files = list(sample_audio_dir.glob("*.wav"))

if audio_files:
    audio_file = audio_files[0]
    print(f"Loading: {audio_file.name}")
    
    audio_data, sample_rate = sf.read(str(audio_file))
    
    if len(audio_data.shape) > 1:
        audio_data = audio_data.mean(axis=1)
    
    duration = len(audio_data) / sample_rate
    
    print(f"\nüìä Audio Properties:")
    print(f"   Sample rate: {sample_rate} Hz")
    print(f"   Duration: {duration:.2f} seconds")
    print(f"   Samples: {len(audio_data):,}")
    print(f"   Data type: {audio_data.dtype}")
    print(f"   Min/Max amplitude: {audio_data.min():.4f} / {audio_data.max():.4f}")
    
    print(f"\nüîä Play Audio:")
    display(Audio(audio_data, rate=sample_rate))
    
    fig, axes = plt.subplots(3, 1, figsize=(14, 10))
    
    time_axis = np.linspace(0, duration, len(audio_data))
    axes[0].plot(time_axis, audio_data, alpha=0.7, linewidth=0.5)
    axes[0].set_xlabel('Time (seconds)', fontsize=12)
    axes[0].set_ylabel('Amplitude', fontsize=12)
    axes[0].set_title(f'Waveform: {audio_file.name}', fontsize=14, fontweight='bold')
    axes[0].grid(alpha=0.3)
    
    zoom_samples = int(2 * sample_rate)
    if len(audio_data) > zoom_samples:
        axes[1].plot(time_axis[:zoom_samples], audio_data[:zoom_samples], alpha=0.8, linewidth=1)
        axes[1].set_xlabel('Time (seconds)', fontsize=12)
        axes[1].set_ylabel('Amplitude', fontsize=12)
        axes[1].set_title('Waveform (First 2 seconds)', fontsize=14, fontweight='bold')
        axes[1].grid(alpha=0.3)
    
    # Spectrogram
    try:
        D = librosa.amplitude_to_db(np.abs(librosa.stft(audio_data)), ref=np.max)
        librosa.display.specshow(D, y_axis='hz', x_axis='time', sr=sample_rate, ax=axes[2])
        axes[2].set_title('Spectrogram', fontsize=14, fontweight='bold')
        axes[2].set_ylabel('Frequency (Hz)', fontsize=12)
        axes[2].set_xlabel('Time (seconds)', fontsize=12)
    except Exception as e:
        axes[2].text(0.5, 0.5, f'Could not generate spectrogram: {e}', 
                    ha='center', va='center', transform=axes[2].transAxes)
        axes[2].set_title('Spectrogram (Error)', fontsize=14)
    
    plt.tight_layout()
    plt.show()
    
    print(f"\nüìà Audio Statistics:")
    rms_energy = np.sqrt(np.mean(audio_data**2))
    zero_crossings = librosa.zero_crossings(audio_data, pad=False).sum()
    zcr = zero_crossings / len(audio_data) * sample_rate
    
    print(f"   RMS Energy: {rms_energy:.4f}")
    print(f"   Zero Crossing Rate: {zcr:.2f} crossings/second")
    print(f"   Dynamic Range: {audio_data.max() - audio_data.min():.4f}")
    
else:
    print("‚ö†Ô∏è  No sample audio files found in sample_audio/ directory")

# %%
print("üîó Audio-Unit Correspondence")
print("=" * 60)

sample_unit_files = list((BASE_DIR / "sample_units").glob("*.units.txt"))
if audio_files and sample_unit_files:
    audio_file = audio_files[0]
    unit_file = sample_unit_files[0]
    
    print(f"Audio: {audio_file.name}")
    print(f"Units: {unit_file.name}")
    
    with open(unit_file, 'r') as f:
        units = [int(u) for u in f.read().strip().split()]
    
    audio_data, sample_rate = sf.read(str(audio_file))
    if len(audio_data.shape) > 1:
        audio_data = audio_data.mean(axis=1)
    
    duration = len(audio_data) / sample_rate
    
    units_per_second = len(units) / duration
    samples_per_unit = len(audio_data) / len(units)
    
    print(f"\nüìä Correspondence:")
    print(f"   Audio duration: {duration:.2f} seconds")
    print(f"   Number of units: {len(units)}")
    print(f"   Units per second: {units_per_second:.2f}")
    print(f"   Samples per unit: {samples_per_unit:.1f}")
    print(f"   Unit frame rate: ~{1/units_per_second*1000:.1f} ms per unit")
    
    fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)
    
    time_axis = np.linspace(0, duration, len(audio_data))
    axes[0].plot(time_axis, audio_data, alpha=0.7, linewidth=0.5, color='steelblue')
    axes[0].set_ylabel('Amplitude', fontsize=12)
    axes[0].set_title('Audio Waveform vs Acoustic Units', fontsize=14, fontweight='bold')
    axes[0].grid(alpha=0.3)
    
    unit_time_axis = np.linspace(0, duration, len(units))
    axes[1].plot(unit_time_axis, units, alpha=0.7, linewidth=0.5, color='coral', marker='.', markersize=2)
    axes[1].set_xlabel('Time (seconds)', fontsize=12)
    axes[1].set_ylabel('Unit ID', fontsize=12)
    axes[1].set_title('Acoustic Unit Sequence', fontsize=14, fontweight='bold')
    axes[1].grid(alpha=0.3)
    axes[1].set_ylim(-5, 105)
    
    plt.tight_layout()
    plt.show()
    
else:
    print("‚ö†Ô∏è  Need both audio and unit files for comparison")

# %%
print("üìè Audio Quality Metrics")
print("=" * 60)

if audio_files:
    audio_file = audio_files[0]
    audio_data, sample_rate = sf.read(str(audio_file))
    if len(audio_data.shape) > 1:
        audio_data = audio_data.mean(axis=1)
    
    audio_data = audio_data / np.max(np.abs(audio_data))
    
    metrics = {}
    
    signal_power = np.mean(audio_data**2)
    noise_estimate = np.std(audio_data - np.mean(audio_data))
    snr_db = 10 * np.log10(signal_power / (noise_estimate**2 + 1e-10))
    metrics['SNR_approx_db'] = snr_db
    
    try:
        spectral_centroid = librosa.feature.spectral_centroid(y=audio_data, sr=sample_rate)
        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_data, sr=sample_rate)
        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)
        metrics['spectral_centroid_hz'] = float(np.mean(spectral_centroid))
        metrics['spectral_rolloff_hz'] = float(np.mean(spectral_rolloff))
        metrics['mfcc_mean'] = [float(np.mean(mfcc)) for mfcc in mfccs]
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not compute spectral features: {e}")
    
    rms = librosa.feature.rms(y=audio_data)[0]
    metrics['rms_mean'] = float(np.mean(rms))
    metrics['rms_std'] = float(np.std(rms))
    
    zcr = librosa.feature.zero_crossing_rate(audio_data)[0]
    metrics['zcr_mean'] = float(np.mean(zcr))
    
    print(f"\nüìä Computed Metrics:")
    def format_metric(value, format_str='.2f'):
        if value == 'N/A' or value is None:
            return 'N/A'
        try:
            return f"{value:{format_str}}"
        except:
            return str(value)
    
    print(f"   Approximate SNR: {format_metric(metrics.get('SNR_approx_db', 'N/A'), '.2f')} dB")
    print(f"   Spectral Centroid: {format_metric(metrics.get('spectral_centroid_hz', 'N/A'), '.1f')} Hz")
    print(f"   Spectral Rolloff: {format_metric(metrics.get('spectral_rolloff_hz', 'N/A'), '.1f')} Hz")
    print(f"   RMS Energy (mean): {format_metric(metrics.get('rms_mean', 'N/A'), '.4f')}")
    print(f"   Zero Crossing Rate: {format_metric(metrics.get('zcr_mean', 'N/A'), '.4f')}")
    
    print(f"\nüí° These metrics can be used to:")
    print(f"   ‚Ä¢ Compare original vs synthesized audio")
    print(f"   ‚Ä¢ Measure audio quality")
    print(f"   ‚Ä¢ Analyze acoustic characteristics")
    print(f"   ‚Ä¢ Validate unit-to-audio reconstruction")
    
else:
    print("‚ö†Ô∏è  No audio files available for analysis")

# %% [markdown]
# ## 6. Testing & Validation
# 
# Test the acoustic tokenization pipeline by comparing original audio with unit sequences.

# %%
print("üß™ Testing Pipeline Validation")
print("=" * 60)

try:
    import joblib
    
    kmeans_path = PHASE1_DIR / "portuguese_kmeans.pkl"
    if kmeans_path.exists():
        kmeans = joblib.load(kmeans_path)
        print(f"‚úì K-Means model loaded: {kmeans.n_clusters} clusters")
        
        # Test: Show cluster centers statistics
        centers = kmeans.cluster_centers_
        print(f"\nüìä Cluster Statistics:")
        print(f"   Number of clusters: {centers.shape[0]}")
        print(f"   Feature dimensions: {centers.shape[1]}")
        print(f"   Center value range: [{centers.min():.4f}, {centers.max():.4f}]")
        print(f"   Mean center norm: {np.mean([np.linalg.norm(c) for c in centers]):.4f}")
        
        if audio_files:
            audio_file = audio_files[0]
            print(f"\nüîç Testing unit prediction on: {audio_file.name}")
            
            if sample_unit_files:
                unit_file = sample_unit_files[0]
                with open(unit_file, 'r') as f:
                    test_units = [int(u) for u in f.read().strip().split()]
                
                valid_units = [u for u in test_units if 0 <= u < kmeans.n_clusters]
                invalid_units = [u for u in test_units if u < 0 or u >= kmeans.n_clusters]
                
                print(f"   Total units: {len(test_units)}")
                print(f"   Valid units (0-{kmeans.n_clusters-1}): {len(valid_units)}")
                if invalid_units:
                    print(f"   ‚ö†Ô∏è  Invalid units found: {len(invalid_units)}")
                else:
                    print(f"   ‚úì All units are valid!")
                
                unit_counts = Counter(test_units)
                print(f"\n   Most common units:")
                for unit, count in unit_counts.most_common(5):
                    print(f"      Unit {unit:3d}: {count:4d} times ({count/len(test_units)*100:.1f}%)")
        
    else:
        print("‚ö†Ô∏è  K-Means model not found")
        
except Exception as e:
    print(f"‚ö†Ô∏è  Error loading K-Means: {e}")
    import traceback
    traceback.print_exc()

print(f"\n‚úÖ Validation complete!")

# %% [markdown]
# ## 4. Summary & Insights
# 
# Key findings from the acoustic tokenization pipeline.

# %%
motif_counts = [m['count'] for m in motif_data['top_motifs']]
motif_percentages = [(c / motif_data['total_tokens']) * 100 for c in motif_counts]

print("üìã Summary & Key Insights")
print("=" * 60)
print("\nüéØ Pipeline Results:")
print(f"   ‚Ä¢ Processed {validation['total_sequences']:,} audio segments")
print(f"   ‚Ä¢ Discovered {motif_data['unique_motifs']} acoustic motifs via BPE")
print(f"   ‚Ä¢ Created {motif_data['total_tokens']:,} total tokens")
print(f"   ‚Ä¢ Average sequence length: {stats['avg_sequence_length']:.1f} units")

print("\nüîç Acoustic Unit Discovery:")
print(f"   ‚Ä¢ K-Means clustering found {stats['expected_unique']} distinct acoustic units")
print(f"   ‚Ä¢ Units represent quantized acoustic features from XLSR-53 model")
print(f"   ‚Ä¢ Unit range: 0-{stats['unit_range'][1]} (covering all discovered units)")

print("\nüéµ Motif Discovery:")
print(f"   ‚Ä¢ Top motif frequency: {motif_percentages[0]:.2f}% of all tokens")
print(f"   ‚Ä¢ Top 10 motifs cover: {sum(motif_percentages[:10]):.2f}% of tokens")
print(f"   ‚Ä¢ Top 20 motifs cover: {sum(motif_percentages[:20]):.2f}% of tokens")
print(f"   ‚Ä¢ This indicates common acoustic patterns in Portuguese speech")

print("\nüí° Applications:")
print("   ‚Ä¢ Text-to-Speech synthesis using discovered units")
print("   ‚Ä¢ Speech recognition using acoustic motifs")
print("   ‚Ä¢ Language modeling for Portuguese audio")
print("   ‚Ä¢ Acoustic pattern analysis and research")

print("\n‚úÖ Analysis Complete!")
print("=" * 60)

